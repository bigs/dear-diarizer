# WavLeJEPA training config for encoder SIGReg sweep (DGX Spark)
# Based on RTX 6000 Pro LR schedule variant (sigreg 0.05).
# LR scaled by sqrt(128/384) â‰ˆ 0.577 from the 384-batch variant.

precision:
  compute_dtype: bfloat16
  loss_in_float32: true

optimizer:
  peak_lr: 1.15e-4
  warmup_steps: 10000
  total_steps: 50000
  weight_decay: 0.04
  grad_clip_norm: 1.0

loss:
  sigreg_weight: 0.05
  num_slices: 256

data:
  batch_size: 128
  sample_rate: 16000
  crop_duration: 2.0
  num_workers: 8
  prefetch_batches: 4

checkpoint:
  checkpoint_dir: checkpoints-batch128-conservative-encsig0p05-dgx-lr2p0e-4-wu10k
  save_every_n_steps: 2500
  keep_n_checkpoints: 3

logging:
  project: wavlejepa
  log_every_n_steps: 50
  eval_every_n_steps: 500

seed: 42
