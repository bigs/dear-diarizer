# WavLeJEPA training config for DGX Spark (GB10)
# Batch 128 - conservative LR for stability
# Recommended: XLA_PYTHON_CLIENT_MEM_FRACTION=0.4 (~48GB)

precision:
  compute_dtype: bfloat16
  loss_in_float32: true

optimizer:
  peak_lr: 1.5e-4
  warmup_steps: 7500
  total_steps: 50000
  weight_decay: 0.04
  grad_clip_norm: 1.0

loss:
  sigreg_weight: 0.02
  num_slices: 256

data:
  batch_size: 128
  sample_rate: 16000
  crop_duration: 2.0

checkpoint:
  checkpoint_dir: checkpoints-batch128-conservative
  save_every_n_steps: 2500
  keep_n_checkpoints: 3

logging:
  project: wavlejepa
  log_every_n_steps: 50
  eval_every_n_steps: 500

seed: 42
