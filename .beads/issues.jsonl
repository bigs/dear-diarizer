{"id":"dear-207","title":"Set up jax-gated-deltanet module structure and GatedDeltaNetConfig","description":"Create jax-gated-deltanet/ directory with __init__.py, config.py (GatedDeltaNetConfig dataclass with head_k_dim, head_v_dim, expand_v, num_heads, num_v_heads, conv_size, use_gate, use_short_conv, etc.)","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T10:14:54.868036-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T10:21:31.186741-05:00","closed_at":"2026-01-16T10:21:31.186741-05:00","close_reason":"Closed"}
{"id":"dear-2ic","title":"Implement LinearAttentionLayer (Mamba-2/RWKV-7 style)","description":"Implement Mamba2-based linear attention layer as an Equinox module, building on mamba2-jax.\n\n## Approach\nUse `mamba2-jax` (added as dependency) for the core SSD algorithm, wrap with Equinox for parameter management.\n\n## Components to Implement\n\n### 1. `RMSNorm` (eqx.Module)\nSimple RMS normalization layer.\n\n### 2. `Mamba2Layer` (eqx.Module)\nSingle Mamba2 layer wrapping `mamba2_jax.ssd.ssd_naive`.\n\nParameters to manage:\n- `in_proj`: Linear projection to (x, B, C, dt)\n- `conv1d`: Depthwise causal convolution\n- `dt_bias`: Time step bias [num_heads]\n- `A_log`: Log of A matrix [num_heads]  \n- `D`: Residual connection weight [num_heads]\n- `norm`: RMSNorm before output\n- `out_proj`: Output projection\n\nInterface:\n```python\ndef __call__(\n    self,\n    x: Float[Array, 'seq_len hidden_dim'],\n    *,\n    initial_state: Optional[Array] = None,\n    return_final_state: bool = False,\n) -\u003e Tuple[Float[Array, 'seq_len hidden_dim'], Optional[Array]]:\n```\n\n### 3. `Mamba2Block` (eqx.Module)\nPre-norm + Mamba2Layer + residual connection.\n\n### 4. `LinearAttentionStack` (eqx.Module)\nStack of Mamba2Blocks that contextualizes frame embeddings.\n\nInterface:\n```python\ndef __call__(\n    self,\n    x: Float[Array, 'seq_len input_dim'],\n) -\u003e Float[Array, 'seq_len hidden_dim']:\n```\n\n## Dependencies\n- `mamba2-jax` (pip package, already added)\n\n## Location\n`generator/mamba.py`\n\n## Parent Epic\ndear-adr","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-15T10:24:07.875912-05:00","created_by":"Cole Brown","updated_at":"2026-01-15T10:56:43.855309-05:00","closed_at":"2026-01-15T10:56:43.855309-05:00","close_reason":"Closed","labels":["task"]}
{"id":"dear-2x8","title":"Configurable SSM backend (Mamba2 vs GatedDeltaNet)","status":"closed","priority":2,"issue_type":"epic","owner":"bigswim@gmail.com","created_at":"2026-01-16T11:23:53.162011-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T11:31:51.712185-05:00","closed_at":"2026-01-16T11:31:51.712185-05:00","close_reason":"Closed"}
{"id":"dear-38t","title":"VoxCeleb1 calibration EER eval (1A)","description":"Implement a fast, repeatable speaker-verification calibration eval using VoxCeleb1 test trials. Scope: load trial pairs, extract embeddings with current WavLeJEPA probe path, L2-normalize, cosine score, compute EER, and write JSON results + CLI usage.","acceptance_criteria":"CLI runs end-to-end on GPU box; outputs EER for VoxCeleb1 test pairs; results saved to JSON with config metadata; brief README usage note.","status":"open","priority":2,"issue_type":"epic","owner":"bigswim@gmail.com","created_at":"2026-01-20T21:26:45.051781-05:00","created_by":"Cole Brown","updated_at":"2026-01-20T21:26:45.051781-05:00","labels":["eval","sv","voxceleb"]}
{"id":"dear-38t.1","title":"Acquire/parse VoxCeleb1 verification trials","description":"Add code to load VoxCeleb1 verification trial list (veri_test.txt) and map relative paths to absolute wav files under voxceleb root. Produce a manifest of unique files to embed and validate missing files with clear errors.","acceptance_criteria":"Parser loads trial list; resolves file paths under a configurable root; reports missing files; unit smoke test or CLI check confirms parsed counts.","status":"open","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-20T21:44:06.204396-05:00","created_by":"Cole Brown","updated_at":"2026-01-20T21:44:06.204396-05:00","labels":["eval","sv","voxceleb"],"dependencies":[{"issue_id":"dear-38t.1","depends_on_id":"dear-38t","type":"parent-child","created_at":"2026-01-20T21:44:06.20647-05:00","created_by":"Cole Brown"}]}
{"id":"dear-3h3","title":"Add tests for SSM backend selection","description":"Test both backends produce valid output. Test config validation (both present = error, neither = error). Test YAML loading.","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T11:24:03.917714-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T11:31:51.696774-05:00","closed_at":"2026-01-16T11:31:51.696774-05:00","close_reason":"Closed","dependencies":[{"issue_id":"dear-3h3","depends_on_id":"dear-2x8","type":"blocks","created_at":"2026-01-16T11:24:09.69813-05:00","created_by":"Cole Brown"},{"issue_id":"dear-3h3","depends_on_id":"dear-eba","type":"blocks","created_at":"2026-01-16T11:24:10.19108-05:00","created_by":"Cole Brown"}]}
{"id":"dear-3wh","title":"Epic: Chunkwise parallel gated delta rule (pure JAX)","description":"Implement chunkwise parallel algorithm for gated delta rule in pure JAX. This is Phase 1 before Pallas kernels - validates the algorithm and gives 2-5x speedup over naive scan.\n\nApproach:\n- Port FLA's chunk algorithm to JAX\n- Use jax.lax.associative_scan for inter-chunk state propagation\n- Add as alternative to naive scan (don't replace)\n- Validate equivalence with tests before switching default\n\nReference: fla-org/flash-linear-attention chunk.py\n\nSubtasks:\n- dear-gnt: Implement chunk utilities and WY representation\n- dear-ekt: Implement intra-chunk delta rule computation (depends on gnt)\n- dear-7ac: Implement inter-chunk state propagation (depends on gnt)\n- dear-ycg: Wire up chunkwise function (depends on ekt, 7ac)\n- dear-lsn: Add equivalence tests (depends on ycg)","status":"closed","priority":2,"issue_type":"epic","owner":"bigswim@gmail.com","created_at":"2026-01-16T10:59:33.95471-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T11:13:36.114915-05:00","closed_at":"2026-01-16T11:13:36.114915-05:00","close_reason":"Closed"}
{"id":"dear-4ua","title":"Update existing YAML configs","description":"Migrate configs/ files to use nested mamba2: section instead of flat params.","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T11:24:03.622606-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T11:29:30.551308-05:00","closed_at":"2026-01-16T11:29:30.551308-05:00","close_reason":"Closed","dependencies":[{"issue_id":"dear-4ua","depends_on_id":"dear-2x8","type":"blocks","created_at":"2026-01-16T11:24:09.634365-05:00","created_by":"Cole Brown"},{"issue_id":"dear-4ua","depends_on_id":"dear-pak","type":"blocks","created_at":"2026-01-16T11:24:10.131057-05:00","created_by":"Cole Brown"}]}
{"id":"dear-5py","title":"Set up evals/ directory structure","description":"Create evals/ subfolder with:\n- evals/__init__.py\n- evals/voxceleb/__init__.py\n- evals/voxceleb/probe.py (main logic)\n- evals/voxceleb/data.py (VoxCeleb data loading)\n\nKeep evaluation code separate from main training code.","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T17:54:55.059904-05:00","created_by":"Cole Brown","updated_at":"2026-01-17T12:30:22.828972-05:00","closed_at":"2026-01-17T12:30:22.828972-05:00","close_reason":"Created evals/ directory structure with __init__ files and stub implementations for data.py and probe.py"}
{"id":"dear-6ym","title":"Implement naive gated_delta_rule recurrence","description":"Implement deltanet.py with gated_delta_rule() using jax.lax.scan. Core math: h = h * exp(g); error = beta * (v - h @ k); h = h + outer(k, error); o = h @ q. This is the Pallas swap-in point.","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T10:14:55.750787-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T10:23:09.829693-05:00","closed_at":"2026-01-16T10:23:09.829693-05:00","close_reason":"Closed","dependencies":[{"issue_id":"dear-6ym","depends_on_id":"dear-207","type":"blocks","created_at":"2026-01-16T10:15:11.734312-05:00","created_by":"Cole Brown"}]}
{"id":"dear-7ac","title":"Implement inter-chunk state propagation","description":"Propagate states between chunks using associative scan or matrix multiply.\n\n- Compute final state of each chunk (assuming zero initial)\n- Use jax.lax.associative_scan or segsum for inter-chunk decay\n- Combine chunk states with proper decay factors\n- Add contribution from initial states to outputs","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T10:59:57.060694-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T11:13:36.075251-05:00","closed_at":"2026-01-16T11:13:36.075251-05:00","close_reason":"Closed","dependencies":[{"issue_id":"dear-7ac","depends_on_id":"dear-gnt","type":"blocks","created_at":"2026-01-16T11:00:13.477557-05:00","created_by":"Cole Brown"}]}
{"id":"dear-7jj","title":"VoxCeleb1 O/E/H SOTA eval suite (2A)","description":"Extend speaker-verification eval to official VoxCeleb1 protocols O/E/H. Scope: ingest protocol trial lists, run scoring pipeline, report EER (and optionally minDCF), and aggregate results in JSON + table.","acceptance_criteria":"O/E/H protocols runnable from CLI; outputs per-protocol metrics to JSON; README/doc notes the standard evaluation settings.","status":"open","priority":2,"issue_type":"epic","owner":"bigswim@gmail.com","created_at":"2026-01-20T21:26:49.973296-05:00","created_by":"Cole Brown","updated_at":"2026-01-20T21:26:49.973296-05:00","labels":["eval","sota","sv","voxceleb"]}
{"id":"dear-7jj.1","title":"Add minDCF to VoxCeleb O/E/H eval","description":"Implement minDCF computation alongside EER in the speaker-verification eval. Make priors/costs configurable via CLI (with sensible defaults) and include them in JSON output for reproducibility.","acceptance_criteria":"CLI supports minDCF params; JSON output includes EER + minDCF per protocol with recorded priors/costs; docs mention defaults.","status":"open","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-20T21:30:14.459658-05:00","created_by":"Cole Brown","updated_at":"2026-01-20T21:30:14.459658-05:00","labels":["eval","sv","voxceleb"],"dependencies":[{"issue_id":"dear-7jj.1","depends_on_id":"dear-7jj","type":"parent-child","created_at":"2026-01-20T21:30:14.461625-05:00","created_by":"Cole Brown"}]}
{"id":"dear-87q","title":"Implement AttractorGenerator main module","description":"Implement the main AttractorGenerator module that orchestrates all components.\n\n## Requirements\n- Integrate LinearAttentionStack, CrossAttention, GRU\n- Implement iterative generation with jax.lax.while_loop\n- Confidence-based early stopping\n- Learned start token for step 0\n- Output: padded attractors array + confidences + valid_count\n\n## Key Implementation Details\n- GRU input at each step: [prev_attractor; cross_attn_output]\n- Step 0 uses learned start_token instead of prev_attractor\n- Hidden state initialized from mean-pooled contextualized frames\n- Generate until confidence \u003c threshold OR max_attractors reached\n\n## Interface\n```python\nclass AttractorGenerator(eqx.Module):\n    def __call__(self, frame_embeddings: Array, *, key) -\u003e tuple[Array, Array, Array]:\n        \"\"\"\n        Args:\n            frame_embeddings: [N, input_dim] from frozen WavLeJEPA\n        Returns:\n            attractors: [max_attractors, attractor_dim]\n            confidences: [max_attractors]\n            valid_count: scalar\n        \"\"\"\n```\n\n## Dependencies\n- LinearAttentionStack\n- CrossAttention\n\n## Parent Epic\ndear-adr","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-15T10:24:44.239087-05:00","created_by":"Cole Brown","updated_at":"2026-01-15T11:07:06.496105-05:00","closed_at":"2026-01-15T11:07:06.496105-05:00","close_reason":"Closed","labels":["task"]}
{"id":"dear-8vd","title":"Implement VoxCeleb data loading","description":"Implement data loading for VoxCeleb1 test set.\n\n## Requirements\n- Download/locate VoxCeleb1 test split\n- Parse speaker IDs from directory structure (id10001, id10002, etc.)\n- Load audio files, resample to 16kHz\n- Return (waveform, speaker_id) pairs\n\n## Interface\n```python\ndef load_voxceleb1_test(root: Path) -\u003e list[tuple[Path, int]]:\n    \"\"\"Returns list of (audio_path, speaker_id) pairs.\"\"\"\n```\n\nConsider using HuggingFace datasets if available.","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T17:54:58.355263-05:00","created_by":"Cole Brown","updated_at":"2026-01-17T12:30:47.873937-05:00","closed_at":"2026-01-17T12:30:47.873937-05:00","close_reason":"Implemented VoxCeleb data loading with speaker ID mapping","dependencies":[{"issue_id":"dear-8vd","depends_on_id":"dear-5py","type":"blocks","created_at":"2026-01-16T17:55:04.37903-05:00","created_by":"Cole Brown"}]}
{"id":"dear-90r","title":"Implement ShortConvolution module","description":"Implement conv.py with ShortConvolution - causal conv1d with configurable kernel size, SiLU activation, supports caching for inference. Similar to Mamba's depthwise conv.","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T10:14:55.425237-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T10:23:09.828282-05:00","closed_at":"2026-01-16T10:23:09.828282-05:00","close_reason":"Closed","dependencies":[{"issue_id":"dear-90r","depends_on_id":"dear-207","type":"blocks","created_at":"2026-01-16T10:15:11.683849-05:00","created_by":"Cole Brown"}]}
{"id":"dear-9fx","title":"Epic: Implement Gated DeltaNet in JAX","description":"Implement Gated DeltaNet (ICLR 2025) in pure JAX/Equinox. Start with naive implementation, structure for future Pallas kernel optimization. Reference: NVlabs/GatedDeltaNet, fla-org/flash-linear-attention. Lives in jax-gated-deltanet/ submodule.\n\nSubtasks:\n- dear-207: Set up module structure and config\n- dear-r7d: Implement RMSNorm and FusedRMSNormGated  \n- dear-90r: Implement ShortConvolution\n- dear-6ym: Implement naive gated_delta_rule recurrence\n- dear-o3b: Implement GatedDeltaNetLayer\n- dear-aqd: Implement GatedDeltaNetBlock and Stack\n- dear-chh: Add tests","status":"closed","priority":2,"issue_type":"epic","owner":"bigswim@gmail.com","created_at":"2026-01-16T10:04:06.271336-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T10:29:20.251255-05:00","closed_at":"2026-01-16T10:29:20.251255-05:00","close_reason":"Closed"}
{"id":"dear-9sn","title":"Create CLI entrypoint for probe evaluation","description":"CLI to run the full probe pipeline.\n\n## Usage\n```bash\nuv run python -m evals.voxceleb.probe \\\n    --checkpoint checkpoints-batch128-conservative/best \\\n    --voxceleb-root /path/to/voxceleb1 \\\n    --output results/voxceleb_probe.json\n```\n\n## Arguments\n- --checkpoint: Path to WavLeJEPA checkpoint\n- --voxceleb-root: Path to VoxCeleb1 dataset\n- --batch-size: Batch size for embedding extraction\n- --output: Where to save results JSON\n\n## Output\nJSON with accuracy metrics + config used.","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T17:54:59.630101-05:00","created_by":"Cole Brown","updated_at":"2026-01-17T12:32:57.907956-05:00","closed_at":"2026-01-17T12:32:57.907956-05:00","close_reason":"Implemented full CLI pipeline: load data, extract embeddings, train probe, save results","dependencies":[{"issue_id":"dear-9sn","depends_on_id":"dear-inc","type":"blocks","created_at":"2026-01-16T17:55:04.576602-05:00","created_by":"Cole Brown"}]}
{"id":"dear-adr","title":"Epic: Implement Speaker Attractor Generator","description":"Implement the Generator component as specified in docs/generator_design.md. This is the second stage of the speaker diarization pipeline that takes WavLeJEPA frame embeddings and produces speaker attractors.\n\n## Key Components\n1. Linear Attention Stack (Mamba-2/RWKV-7 style)\n2. Cross-Attention Module\n3. GRU-based Recurrent Generator\n4. Energy-based training objective\n5. Test-time optimization\n\n## Architecture Flow\n```\nWavLeJEPA (frozen) → Linear Attention Stack → Contextualized Frames\n                                                    ↓\n                                              Cross-Attention ← GRU hidden\n                                                    ↓\n                                              GRU → attractor + confidence\n                                              (loop until confidence \u003c θ)\n```\n\nSee docs/generator_design.md for full specification.","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-15T10:23:03.102164-05:00","created_by":"Cole Brown","updated_at":"2026-01-15T17:32:53.640306-05:00","closed_at":"2026-01-15T17:32:53.640306-05:00","close_reason":"Closed","labels":["epic"]}
{"id":"dear-aqd","title":"Implement GatedDeltaNetBlock and Stack","description":"Implement GatedDeltaNetBlock (pre-norm + GatedDeltaNetLayer + residual) and GatedDeltaNetStack (input projection + N blocks + final norm). Match generator/mamba.py patterns.","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T10:14:56.356155-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T10:25:13.349373-05:00","closed_at":"2026-01-16T10:25:13.349373-05:00","close_reason":"Closed","dependencies":[{"issue_id":"dear-aqd","depends_on_id":"dear-o3b","type":"blocks","created_at":"2026-01-16T10:15:12.372794-05:00","created_by":"Cole Brown"}]}
{"id":"dear-bwn","title":"Create synthetic multi-speaker test data","description":"Create synthetic test data for developing and testing the Generator.\n\n## Requirements\n- Generate fake 'frame embeddings' that simulate multi-speaker audio\n- Should have clear cluster structure (each speaker = distinct cluster)\n- Variable number of speakers (1-10)\n- Variable segment lengths per speaker\n- Should be reproducible (seeded RNG)\n\n## Use Cases\n- Unit testing energy functions\n- Integration testing full generator\n- Debugging training loop\n- Visualizing attractor quality\n\n## Suggested Approach\n```python\ndef make_synthetic_data(\n    num_speakers: int,\n    frames_per_speaker: int,\n    embedding_dim: int = 768,\n    noise_scale: float = 0.1,\n    key: PRNGKey\n) -\u003e tuple[Array, Array]:\n    \"\"\"\n    Returns:\n        frame_embeddings: [N, D] where N = num_speakers * frames_per_speaker\n        speaker_labels: [N] ground truth (for evaluation only)\n    \"\"\"\n```\n\n## Parent Epic\ndear-adr","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-15T10:25:30.054594-05:00","created_by":"Cole Brown","updated_at":"2026-01-15T11:24:55.622556-05:00","closed_at":"2026-01-15T11:24:55.622556-05:00","close_reason":"Closed","labels":["task"]}
{"id":"dear-c3w","title":"Epic: VoxCeleb Linear Probe Evaluation","description":"Implement speaker identification linear probe on VoxCeleb1 to evaluate WavLeJEPA representation quality.\n\n## Approach\n- Freeze WavLeJEPA encoder (stop gradients)\n- Extract frame embeddings → mean pool → utterance embedding\n- Train linear classifier (768 → num_speakers)\n- Report top-1/top-5 accuracy\n\n## Requirements\n- Specify checkpoint path from checkpoints dir\n- Isolated in `evals/` subfolder\n- Clean CLI interface\n\n## Success Criteria\n- 20-40% accuracy suggests representations capture speaker info\n- Lower accuracy doesn't invalidate model, just means aggregation matters","status":"closed","priority":2,"issue_type":"epic","owner":"bigswim@gmail.com","created_at":"2026-01-16T17:54:36.87485-05:00","created_by":"Cole Brown","updated_at":"2026-01-17T12:33:02.980791-05:00","closed_at":"2026-01-17T12:33:02.980791-05:00","close_reason":"Complete! Implemented VoxCeleb linear probe with data loading, embedding extraction, and evaluation."}
{"id":"dear-chh","title":"Add tests for jax-gated-deltanet","description":"Add tests: 1) gated_delta_rule matches expected output for simple case, 2) GatedDeltaNetLayer forward pass shapes, 3) Stack forward pass, 4) Gradient flow through all components.","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T10:14:56.615828-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T10:29:20.249656-05:00","closed_at":"2026-01-16T10:29:20.249656-05:00","close_reason":"Closed","dependencies":[{"issue_id":"dear-chh","depends_on_id":"dear-aqd","type":"blocks","created_at":"2026-01-16T10:15:12.419114-05:00","created_by":"Cole Brown"}]}
{"id":"dear-d0d","title":"Implement embedding extraction from checkpoint","description":"Extract utterance embeddings from frozen WavLeJEPA checkpoint.\n\n## Requirements\n- Load checkpoint from specified path (Orbax format)\n- Stop gradients to encoder (jax.lax.stop_gradient)\n- Process: audio → WaveformEncoder → ContextEncoder → mean pool\n- Batch processing for efficiency\n\n## Interface\n```python\ndef extract_embeddings(\n    checkpoint_path: Path,\n    audio_paths: list[Path],\n    batch_size: int = 32,\n) -\u003e np.ndarray:  # [num_utterances, 768]\n```","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T17:54:58.730378-05:00","created_by":"Cole Brown","updated_at":"2026-01-17T12:31:36.486491-05:00","closed_at":"2026-01-17T12:31:36.486491-05:00","close_reason":"Implemented embedding extraction with frozen encoder and mean pooling","dependencies":[{"issue_id":"dear-d0d","depends_on_id":"dear-5py","type":"blocks","created_at":"2026-01-16T17:55:04.430714-05:00","created_by":"Cole Brown"}]}
{"id":"dear-eba","title":"Update LinearAttentionStack factory logic","description":"Check which SSM config is present and instantiate Mamba2Block or GatedDeltaNetBlock accordingly. Import GatedDeltaNetBlock from jax_gated_deltanet.","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T11:24:03.346639-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T11:28:40.539747-05:00","closed_at":"2026-01-16T11:28:40.539747-05:00","close_reason":"Closed","dependencies":[{"issue_id":"dear-eba","depends_on_id":"dear-2x8","type":"blocks","created_at":"2026-01-16T11:24:09.569272-05:00","created_by":"Cole Brown"},{"issue_id":"dear-eba","depends_on_id":"dear-pak","type":"blocks","created_at":"2026-01-16T11:24:10.072143-05:00","created_by":"Cole Brown"}]}
{"id":"dear-ekt","title":"Implement intra-chunk delta rule computation","description":"Compute outputs within each chunk using the WY representation. This handles the O(chunk²) parallel work within each chunk.\n\n- Compute w, u from WY representation  \n- Compute local (diagonal) outputs\n- Handle the delta rule update in parallel within chunk","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T10:59:51.486369-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T11:13:36.061923-05:00","closed_at":"2026-01-16T11:13:36.061923-05:00","close_reason":"Closed","dependencies":[{"issue_id":"dear-ekt","depends_on_id":"dear-gnt","type":"blocks","created_at":"2026-01-16T11:00:13.406068-05:00","created_by":"Cole Brown"}]}
{"id":"dear-gnt","title":"Implement chunk utilities and WY representation","description":"Implement helper functions for chunkwise algorithm:\n- segment sum (stable cumsum for decay computation)\n- solve_tril (triangular solve for WY representation)\n- chunk reshaping utilities\n- A matrix computation (scaled k @ k.T with gating)\n\nReference: FLA's chunk_scaled_dot_kkt, solve_tril, wy_fast.py","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T10:59:46.065478-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T11:13:36.046772-05:00","closed_at":"2026-01-16T11:13:36.046772-05:00","close_reason":"Closed"}
{"id":"dear-hmz","title":"Extract Mamba2Config from GeneratorConfig","description":"Create Mamba2Config dataclass with state_size, chunk_size, time_step_*, A_initializer_range params. Remove from GeneratorConfig top level.","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T11:24:02.684707-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T11:26:22.00447-05:00","closed_at":"2026-01-16T11:26:22.00447-05:00","close_reason":"Closed","dependencies":[{"issue_id":"dear-hmz","depends_on_id":"dear-2x8","type":"blocks","created_at":"2026-01-16T11:24:09.434652-05:00","created_by":"Cole Brown"}]}
{"id":"dear-ile","title":"Implement test-time optimization loop","description":"Implement attractor refinement via energy minimization at inference.\n\n## Specification\n```python\ndef refine_attractors(A_init, X, num_steps=50, lr=0.01):\n    A = A_init\n    for _ in range(num_steps):\n        grad_A = grad(E, argnums=0)(A, X)\n        A = A - lr * grad_A\n    return A\n```\n\n## Requirements\n- Gradient descent on energy w.r.t. attractors only\n- Configurable: num_steps, learning_rate\n- Consider stopping criteria based on energy convergence\n- May need attractor re-normalization after gradient steps\n- Must handle masking for invalid attractors\n\n## Parent Epic\ndear-adr","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-15T10:25:14.661784-05:00","created_by":"Cole Brown","updated_at":"2026-01-15T11:30:46.039708-05:00","closed_at":"2026-01-15T11:30:46.039708-05:00","close_reason":"Closed","labels":["task"]}
{"id":"dear-inc","title":"Implement linear probe training and evaluation","description":"Train and evaluate linear classifier on extracted embeddings.\n\n## Requirements\n- Split embeddings into train/test (80/20 stratified by speaker)\n- Train LogisticRegression or single Linear layer\n- Report: top-1 accuracy, top-5 accuracy, per-class breakdown\n\n## Interface\n```python\ndef train_linear_probe(\n    embeddings: np.ndarray,  # [N, 768]\n    labels: np.ndarray,      # [N]\n    test_size: float = 0.2,\n) -\u003e dict:  # {\"top1\": float, \"top5\": float, ...}\n```","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T17:54:59.187455-05:00","created_by":"Cole Brown","updated_at":"2026-01-17T12:32:21.936906-05:00","closed_at":"2026-01-17T12:32:21.936906-05:00","close_reason":"Implemented linear probe with train/test split and optional cross-validation","dependencies":[{"issue_id":"dear-inc","depends_on_id":"dear-d0d","type":"blocks","created_at":"2026-01-16T17:55:04.480652-05:00","created_by":"Cole Brown"},{"issue_id":"dear-inc","depends_on_id":"dear-8vd","type":"blocks","created_at":"2026-01-16T17:55:04.52774-05:00","created_by":"Cole Brown"}]}
{"id":"dear-kgw","title":"Implement energy functions","description":"Implement the energy-based objective functions for training.\n\n## Energy Components\n\n### E_assignment (Frame-to-Attractor)\n```python\nd_ik = ||x_i - a_k||²                 # L2 squared distance\nw_ik = softmax(-d_ik / τ)            # soft assignment (softmin)\nE_assignment = (1/N) * Σ_i Σ_k w_ik * d_ik\n```\n\n### E_separation (Attractor Diversity)\n```python\nE_separation = Σ_{k≠j} max(0, margin - ||a_k - a_j||)\n```\nHinge loss with configurable margin.\n\n### E_coverage (No Orphan Frames) - Optional\n```python\nusage_k = Σ_i w_ik\nE_coverage = Σ_k max(0, min_usage - usage_k)\n```\n\n## Combined Energy\n```python\nE(A, X) = E_assignment + λ_sep * E_separation + λ_cov * E_coverage\n```\n\n## Requirements\n- All functions must be JAX-differentiable\n- Temperature τ should be a parameter (for annealing)\n- Must handle variable number of valid attractors (masking)\n\n## Parent Epic\ndear-adr","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-15T10:24:56.402514-05:00","created_by":"Cole Brown","updated_at":"2026-01-15T11:12:49.924457-05:00","closed_at":"2026-01-15T11:12:49.924457-05:00","close_reason":"Closed","labels":["task"]}
{"id":"dear-lsn","title":"Add equivalence tests for chunkwise vs naive","description":"Validate chunkwise implementation matches naive scan:\n- Test output equivalence (allclose with tolerance)\n- Test final state equivalence\n- Test with various seq lengths (divisible, non-divisible by chunk_size)\n- Test with/without initial state\n- Test gradient equivalence\n- Benchmark comparison (optional)","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T11:00:08.379286-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T11:13:36.101843-05:00","closed_at":"2026-01-16T11:13:36.101843-05:00","close_reason":"Closed","dependencies":[{"issue_id":"dear-lsn","depends_on_id":"dear-ycg","type":"blocks","created_at":"2026-01-16T11:00:13.698417-05:00","created_by":"Cole Brown"}]}
{"id":"dear-mfk","title":"Implement CrossAttention module","description":"Implement multi-head cross-attention for querying contextualized frames from GRU hidden state.\n\n## Requirements\n- Multi-head attention (configurable num_heads)\n- Query: GRU hidden state [D]\n- Key/Value: contextualized frames [N, D]\n- Output: attended context vector [D]\n\n## Interface\n```python\nclass CrossAttention(eqx.Module):\n    num_heads: int\n    head_dim: int\n    w_q: eqx.nn.Linear\n    w_k: eqx.nn.Linear\n    w_v: eqx.nn.Linear\n    w_o: eqx.nn.Linear\n    \n    def __call__(self, query: Array, kv: Array) -\u003e Array:\n        \"\"\"\n        Args:\n            query: [D] GRU hidden state\n            kv: [N, D] contextualized frames\n        Returns:\n            [D] attended context vector\n        \"\"\"\n```\n\n## Parent Epic\ndear-adr","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-15T10:24:29.164819-05:00","created_by":"Cole Brown","updated_at":"2026-01-15T11:01:04.73503-05:00","closed_at":"2026-01-15T11:01:04.73503-05:00","close_reason":"Closed","labels":["task"]}
{"id":"dear-mhy","title":"Implement LinearAttentionStack","description":"Implement the stack of gated linear attention layers that contextualizes frame embeddings.\n\n## Requirements\n- Stack 4-6 LinearAttentionLayer modules\n- Configurable via GeneratorConfig.num_layers\n- Maintains sequence length (no pooling)\n\n## Interface\n```python\nclass LinearAttentionStack(eqx.Module):\n    layers: list[LinearAttentionLayer]\n    \n    def __call__(self, x: Array) -\u003e Array:\n        \"\"\"Process frame embeddings through all layers.\n        \n        Args:\n            x: [N, D] frame embeddings\n        Returns:\n            [N, D] contextualized frame representations\n        \"\"\"\n```\n\n## Dependencies\n- Requires LinearAttentionLayer implementation\n\n## Parent Epic\ndear-adr","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-15T10:24:18.737134-05:00","created_by":"Cole Brown","updated_at":"2026-01-15T10:58:01.628143-05:00","closed_at":"2026-01-15T10:58:01.628143-05:00","close_reason":"Closed","labels":["task"]}
{"id":"dear-ngw","title":"Implement GeneratorConfig dataclass","description":"Implement the configuration dataclass for the Generator.\n\n## Fields\n```python\n@dataclass\nclass GeneratorConfig:\n    # Dimensions\n    input_dim: int = 768          # WavLeJEPA output dim\n    hidden_dim: int = 768         # GRU hidden size\n    attractor_dim: int = 768      # Output attractor dimension\n    \n    # Linear attention stack\n    num_layers: int = 4           # Number of linear attention layers\n    \n    # Cross-attention\n    num_heads: int = 8            # Multi-head attention heads\n    \n    # Generation\n    max_attractors: int = 10      # Maximum speakers\n    confidence_threshold: float = 0.5\n    \n    # Energy weights\n    lambda_separation: float = 1.0\n    lambda_coverage: float = 0.1\n    separation_margin: float = 1.0\n    \n    # Temperature annealing\n    tau_start: float = 1.0\n    tau_end: float = 0.1\n    \n    # Confidence training\n    usage_threshold: float = 0.5  # seconds\n```\n\n## Parent Epic\ndear-adr","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-15T10:25:19.793439-05:00","created_by":"Cole Brown","updated_at":"2026-01-15T10:59:37.268067-05:00","closed_at":"2026-01-15T10:59:37.268067-05:00","close_reason":"Closed","labels":["task"]}
{"id":"dear-o3b","title":"Implement GatedDeltaNetLayer","description":"Implement layers.py GatedDeltaNetLayer: q/k/v/a/b projections, short convs on q/k/v, L2 norm on q/k, call gated_delta_rule, output gating with FusedRMSNormGated, output projection. Follow FLA structure.","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T10:14:56.078846-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T10:25:13.347804-05:00","closed_at":"2026-01-16T10:25:13.347804-05:00","close_reason":"Closed","dependencies":[{"issue_id":"dear-o3b","depends_on_id":"dear-r7d","type":"blocks","created_at":"2026-01-16T10:15:12.025656-05:00","created_by":"Cole Brown"},{"issue_id":"dear-o3b","depends_on_id":"dear-90r","type":"blocks","created_at":"2026-01-16T10:15:12.066394-05:00","created_by":"Cole Brown"},{"issue_id":"dear-o3b","depends_on_id":"dear-6ym","type":"blocks","created_at":"2026-01-16T10:15:12.107166-05:00","created_by":"Cole Brown"}]}
{"id":"dear-pak","title":"Update GeneratorConfig with nested SSM configs","description":"Add Optional[Mamba2Config] and Optional[GatedDeltaNetConfig] fields. Add validation: exactly one must be provided. Update property methods.","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T11:24:03.038816-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T11:26:22.01906-05:00","closed_at":"2026-01-16T11:26:22.01906-05:00","close_reason":"Closed","dependencies":[{"issue_id":"dear-pak","depends_on_id":"dear-2x8","type":"blocks","created_at":"2026-01-16T11:24:09.503174-05:00","created_by":"Cole Brown"},{"issue_id":"dear-pak","depends_on_id":"dear-hmz","type":"blocks","created_at":"2026-01-16T11:24:10.012373-05:00","created_by":"Cole Brown"}]}
{"id":"dear-r7d","title":"Implement RMSNorm and FusedRMSNormGated","description":"Implement norm.py with RMSNorm (reuse from generator/) and FusedRMSNormGated (RMSNorm that takes a gate tensor and multiplies output by sigmoid(gate)).","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T10:14:55.154734-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T10:23:09.826459-05:00","closed_at":"2026-01-16T10:23:09.826459-05:00","close_reason":"Closed","dependencies":[{"issue_id":"dear-r7d","depends_on_id":"dear-207","type":"blocks","created_at":"2026-01-16T10:15:11.632547-05:00","created_by":"Cole Brown"}]}
{"id":"dear-tj6","title":"Diarization eval baseline (2B)","description":"Build a baseline diarization evaluation pipeline to measure DER/JER using WavLeJEPA frame-level embeddings. Scope: dataset selection (AMI/DIHARD/CallHome TBD), frame extraction, clustering (AHC or spectral), VAD handling (oracle first), and metrics report.","acceptance_criteria":"Chosen dataset documented; CLI runs end-to-end; reports DER/JER (with oracle VAD at minimum); results saved to JSON + brief usage notes.","status":"open","priority":2,"issue_type":"epic","owner":"bigswim@gmail.com","created_at":"2026-01-20T21:26:55.05612-05:00","created_by":"Cole Brown","updated_at":"2026-01-20T21:26:55.05612-05:00","labels":["diarization","eval"]}
{"id":"dear-tj6.1","title":"Research EEND-EDA / EEND-TA eval protocols","description":"Use Exa web search to summarize EEND-EDA and EEND-TA evaluation protocols: datasets used, preprocessing/VAD assumptions, metrics (DER/JER), and any reported baselines. Capture any implementation details needed to align our diarization eval with the papers.","acceptance_criteria":"Short writeup with citations/links; clear list of datasets, metrics, and protocol choices; recommendations for aligning our DIHARD eval.","notes":"Research summary: EEND-TA paper (arXiv:2312.06253) uses simulated LibriSpeech mixtures for pretraining; fine-tunes/evals on DIHARD III, VoxConverse, MagicData-RAMC, AMI Mix, AMI SDM1; reports DER as primary metric. EEND-EDA paper (arXiv:2005.09921) explicitly reports CALLHOME (2-spk + unknown spk); AMI/DIHARD appear more in later EEND variants. DIHARD official scoring reports DER/JER (core/full). For alignment: DIHARD III + official scorer, report DER/JER; start with oracle VAD.","status":"open","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-20T21:30:19.059652-05:00","created_by":"Cole Brown","updated_at":"2026-01-20T21:33:12.312836-05:00","labels":["diarization","eval","research"],"dependencies":[{"issue_id":"dear-tj6.1","depends_on_id":"dear-tj6","type":"parent-child","created_at":"2026-01-20T21:30:19.061749-05:00","created_by":"Cole Brown"}]}
{"id":"dear-wk2","title":"Set up training loop with temperature annealing","description":"Implement the training loop for the Generator with deterministic annealing.\n\n## Requirements\n- Training objective: L = E(A, X) + λ_conf * L_confidence\n- Temperature annealing: τ goes from tau_start (soft) to tau_end (hard) over training\n- Frozen WavLeJEPA encoder (no gradients)\n- Trainable: LinearAttentionStack, CrossAttention, GRU, output heads\n\n## Training Flow\n1. Encode audio with frozen WavLeJEPA\n2. Pass through linear attention stack\n3. Generate attractors with GRU\n4. Compute energy loss + confidence loss\n5. Backprop through generator only\n\n## Considerations\n- Learning rate schedule\n- Gradient clipping\n- Checkpointing\n- Logging (loss components, attractor counts, etc.)\n\n## Parent Epic\ndear-adr","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-15T10:25:24.926136-05:00","created_by":"Cole Brown","updated_at":"2026-01-15T17:27:46.727641-05:00","closed_at":"2026-01-15T17:27:46.727641-05:00","close_reason":"Closed","labels":["task"]}
{"id":"dear-ycg","title":"Wire up chunkwise gated_delta_rule_chunk function","description":"Combine all components into gated_delta_rule_chunk():\n- Same signature as gated_delta_rule (drop-in replacement)\n- Chunk input sequences\n- Call intra-chunk computation\n- Call inter-chunk propagation  \n- Combine outputs and reshape back\n- Handle edge cases (non-divisible seq len, initial state)","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-16T11:00:03.234399-05:00","created_by":"Cole Brown","updated_at":"2026-01-16T11:13:36.088828-05:00","closed_at":"2026-01-16T11:13:36.088828-05:00","close_reason":"Closed","dependencies":[{"issue_id":"dear-ycg","depends_on_id":"dear-ekt","type":"blocks","created_at":"2026-01-16T11:00:13.553837-05:00","created_by":"Cole Brown"},{"issue_id":"dear-ycg","depends_on_id":"dear-7ac","type":"blocks","created_at":"2026-01-16T11:00:13.625004-05:00","created_by":"Cole Brown"}]}
{"id":"dear-yne","title":"Implement confidence head training loss","description":"Implement the auxiliary usage-based confidence loss.\n\n## Specification\n```python\nusage_k = Σ_i w_ik                           # total soft-assignment mass\ntarget_k = 1 if usage_k \u003e threshold else 0   # threshold ≈ 0.5s audio\nL_confidence = (1/K) * Σ_k BCE(c_k, target_k)\n```\n\n## Requirements\n- Binary cross-entropy loss\n- Usage threshold configurable (default: frames equivalent to 0.5s audio)\n- Must handle masking for invalid attractors\n- Ensures confidence is self-consistent with energy function\n\n## Dependencies\n- Soft assignment weights from energy function (w_ik)\n\n## Parent Epic\ndear-adr","status":"closed","priority":2,"issue_type":"task","owner":"bigswim@gmail.com","created_at":"2026-01-15T10:25:09.531043-05:00","created_by":"Cole Brown","updated_at":"2026-01-15T11:24:50.546459-05:00","closed_at":"2026-01-15T11:24:50.546459-05:00","close_reason":"Closed","labels":["task"]}
