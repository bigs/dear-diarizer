\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{hyperref}

\geometry{a4paper, margin=1in}

\title{Dear Diarizer: Vision and Objectives}
\author{Cole Brown, Kiosk}
\date{\today}

\begin{document}

\maketitle

\section{Introduction}
\textit{Dear Diarizer} is a research engineering project aimed at exploring novel energy-based models (EBMs) for speaker diarization.

The primary objective is to leverage self-supervised learning (SSL) to the fullest extent possible, moving away from purely supervised classification paradigms. The system is designed to handle arbitrarily long audio recordings while maintaining consistent speaker identity prediction through a pseudo-online learning approach.

\section{Motivation: Limitations of Prior Art}
Current state-of-the-art methods, such as EEND-EDA \cite{horiguchi2022endtoend}, have demonstrated impressive capabilities in handling overlapping speech and flexible speaker counts. However, they rely heavily on global attention mechanisms to maintain speaker consistency. EEND-EDA employs a two-phase approach: first generating speaker "attractors" by attending to the entire audio sequence, and subsequently assigning speech activity to these attractors.

This global dependency presents a critical limitation: it necessitates processing the entire audio file in a single pass to ensure speaker consistency. For long-form audio where the full context cannot fit into memory, the process must be split into chunks, breaking the global speaker identity tracking (e.g., "Speaker 1" in chunk A may be "Speaker 3" in chunk B).

\section{Architecture}
Our goal is to overcome these limitations by introducing a \textit{pseudo-online} process that operates on energy "basins" of attraction. In this framework, speakers are dynamically added to an energy landscape as they are discovered. We then utilize an energy minimization technique to fit audio samples to these speaker basins, preserving identity consistency without requiring global attention over the entire duration.

The proposed architecture consists of two primary stages: a robust self-supervised frontend and an energy-based downstream network.

\subsection{Stage 1: Self-Supervised Frontend (WavJEPA)}
 The first stage involves a high-capacity encoder responsible for building rich, contextualized representations of human speech. 
\begin{itemize}
        \item \textbf{Model}: We aim to utilize or adapt the \textbf{WavJEPA} (Joint Embedding Predictive Architecture) framework \cite{yuksel2025wavjepa}.
        \item \textbf{Goal}: To generate high-quality latent representations of audio without relying on labeled speaker data during pre-training.
        \item \textbf{Scope}: Initially constrained to English language speech, with future potential for multilingual expansion.
    \end{itemize}
    
    \subsection{Stage 2: Energy-Based Diarization}
    Downstream of the encoder, we introduce an energy-based network designed to disentangle and track speakers.
    \begin{itemize}
        \item \textbf{Concept}: Instead of standard softmax classification, the model learns an energy function $E(x, y)$, where low energy corresponds to compatible pairs of (audio segment, speaker identity).
        \item \textbf{Online Consistency}: A core challenge in diarization is "permutation ambiguity" over long durations. This component will employ \textbf{pseudo-online learning} to dynamically update speaker prototypes or energy manifolds as the audio stream progresses, ensuring that "Speaker A" at minute 1 remains "Speaker A" at minute 60.
    \end{itemize}
    
    \section{Roadmap}
    \begin{enumerate}
        \item Setup and reproduction of baseline WavJEPA inference.
        \item Design of the EBM objective function for speaker clustering.
        \item Implementation of the pseudo-online update mechanism.
    \end{enumerate}
    
    \bibliographystyle{plain}
    \bibliography{refs}
    
    \end{document}